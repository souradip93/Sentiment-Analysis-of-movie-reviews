{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment9A.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souradip93/CS69002_9A_18CS60R07/blob/master/Assignment9A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "O0K36BR3ZPSi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Import the libraries**"
      ]
    },
    {
      "metadata": {
        "id": "BesUUps3M_7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dDx9g4CZqjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Upload Train file**"
      ]
    },
    {
      "metadata": {
        "id": "zhHOa6nOSu0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Option 1 - Upload the trainig dataset"
      ]
    },
    {
      "metadata": {
        "id": "D97pCVdLS04m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.txt'].decode('utf-8')), sep='\\t')\n",
        "df_train.head()\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.txt'].decode('utf-8')), sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4bkGwjqS4LP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*OR*\n",
        "\n",
        "Option 2 - Store the file in your google drive account"
      ]
    },
    {
      "metadata": {
        "id": "XgJRhFGl9Gad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "87ec0b57-373c-496f-ff9e-427d2e842937"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Train_20K.txt', sep='\\t')\n",
        "df_train.head()\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Test_5K.txt', sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>as always this is an inaccurate picture of the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did the movie-makers even preview this before ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Heavily re-edited and often confusing, the ori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I notice that most of the people who think thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First of all, this is a low-budget movie, so m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  as always this is an inaccurate picture of the...      0\n",
              "1  Did the movie-makers even preview this before ...      0\n",
              "2  Heavily re-edited and often confusing, the ori...      0\n",
              "3  I notice that most of the people who think thi...      0\n",
              "4  First of all, this is a low-budget movie, so m...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "OcrHdv2VQ2Qu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_X = df_train['text'].astype(str).tolist()\n",
        "train_data_Y = df_train['label'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tisd3JloqbOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data_X = df_test['text'].astype(str).tolist()\n",
        "test_data_Y = df_test['label'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1cYXFJtETb0a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "metadata": {
        "id": "kECKJFLbTrD-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Remove br tags and numbers"
      ]
    },
    {
      "metadata": {
        "id": "akSG_F8yWKh_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_br_tags_and_numbers(train_data_X):\n",
        "  import re\n",
        "  regex = re.compile(r'<.*?>|\\d+')\n",
        "  train_data_X = [regex.sub(' ', x) for x in train_data_X]\n",
        "  train_data_X = [x.replace(\"'\", '').replace('\\n\\n', ' ') for x in train_data_X]\n",
        "  return train_data_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhOfwbIkTzUn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Tokenize - Consider only alphanumeric characters"
      ]
    },
    {
      "metadata": {
        "id": "-8dXaj3SQyWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(train_data_X):\n",
        "  from nltk.tokenize import RegexpTokenizer\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  train_data_X = [tokenizer.tokenize(x) for x in train_data_X]\n",
        "  #train_data_X = [x.split(' ') for x in train_data_X]\n",
        "  #train_data_X = [[y for y in x if y != ''] for x in train_data_X]\n",
        "  #train_data_X[0], train_data_Y[0]\n",
        "  return train_data_X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-158l3wT9D_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Convert to lower case"
      ]
    },
    {
      "metadata": {
        "id": "lLLIjYb5Qc9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_lower(train_data_X):\n",
        "  train_data_X = [[y.lower() for y in x] for x in train_data_X]\n",
        "  #train_data_X[0], train_data_Y[0]\n",
        "  return train_data_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1d2fjmatUAqV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. Remove stopwords"
      ]
    },
    {
      "metadata": {
        "id": "i0bZVBGlX5TF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_stopwords(train_data_X):\n",
        "  from nltk.corpus import stopwords\n",
        "  nltk.download('stopwords')\n",
        "  stopword_set = set(stopwords.words('english'))\n",
        "  train_data_X = [[y for y in x if y not in stopword_set] for x in train_data_X]\n",
        "  #train_data_X[0], train_data_Y[0]\n",
        "  return train_data_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iM9RmpYmUDXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5. Perform lemmatization"
      ]
    },
    {
      "metadata": {
        "id": "Zc3IRBb5bNo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lemmatize(train_data_X):\n",
        "  from nltk.stem import WordNetLemmatizer \n",
        "  nltk.download('wordnet')\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  train_data_X = [[lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(y,'n'), 'v'), 'a'), 'r') for y in x] for x in train_data_X]\n",
        "  return train_data_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3ek7Ra2KZXb3"
      },
      "cell_type": "markdown",
      "source": [
        "6. Remove punctuation"
      ]
    },
    {
      "metadata": {
        "id": "3Bh0ZpU-rY8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_punctuation(train_data_X):\n",
        "  import string\n",
        "  table = str.maketrans(' ', ' ', string.punctuation)\n",
        "  train_data_X = [x.translate(table) for x in train_data_X]\n",
        "  return train_data_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bc293MWsU5C7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocessing on Training data**"
      ]
    },
    {
      "metadata": {
        "id": "lod_N-s9itSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f30c19fd-cd50-4cba-919e-27f002ea76c8"
      },
      "cell_type": "code",
      "source": [
        "train_data_X = remove_br_tags_and_numbers(train_data_X)\n",
        "#train_data_X = remove_punctuation(train_data_X)\n",
        "train_data_X = tokenize(train_data_X)\n",
        "train_data_X = convert_to_lower(train_data_X)\n",
        "train_data_X = remove_stopwords(train_data_X)\n",
        "train_data_X = lemmatize(train_data_X)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fip3k6R2VAOS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocessing on Test data**"
      ]
    },
    {
      "metadata": {
        "id": "58o-WKWaTBnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33e22c58-7831-485a-9ea5-6977599e3c8d"
      },
      "cell_type": "code",
      "source": [
        "test_data_X = remove_br_tags_and_numbers(test_data_X)\n",
        "#test_data_X = remove_punctuation(test_data_X)\n",
        "test_data_X = tokenize(test_data_X)\n",
        "test_data_X = convert_to_lower(test_data_X)\n",
        "test_data_X = remove_stopwords(test_data_X)\n",
        "test_data_X = lemmatize(test_data_X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FW5yVYrTVIMz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Reduce Vocab**"
      ]
    },
    {
      "metadata": {
        "id": "sSTOY6tBQmDI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_frequency(dataset):\n",
        "  word_frequency = {}\n",
        "  for sent in dataset:\n",
        "      for word in sent:\n",
        "          if word not in word_frequency:\n",
        "              word_frequency[word] = 1\n",
        "          else:\n",
        "              val = word_frequency[word]\n",
        "              val += 1\n",
        "              word_frequency[word] = val\n",
        "              \n",
        "  #word_to_ix['UNKNOWN'] = len(word_to_ix)\n",
        "  return word_frequency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ceaiZIgr6ilO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "THRESHOLD_FREQUENCY = 10\n",
        "\n",
        "def reduce_vocab(word_frequency):\n",
        "  word_to_ix = {}\n",
        "  for word in word_frequency:\n",
        "    val = word_frequency[word]\n",
        "    if val >= THRESHOLD_FREQUENCY:\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "  word_to_ix['UNKNOWN'] = len(word_to_ix)\n",
        "  return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZN2SRkFjTosC",
        "colab_type": "code",
        "outputId": "3b775d34-3de3-4f2d-92fe-0abf5d267836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_frequency = generate_word_frequency(train_data_X + test_data_X)\n",
        "word_to_ix = reduce_vocab(word_frequency)\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3gmilFZDYnvp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Store the word index once created"
      ]
    },
    {
      "metadata": {
        "id": "TuMDtUxDW_f_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"word_to_ix.pickle\",\"wb\")\n",
        "pickle.dump(word_to_ix, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "from google.colab import files\n",
        "model = files.download(\"word_to_ix.pickle\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zsOMMvoKI5-2"
      },
      "cell_type": "markdown",
      "source": [
        "#**Reduce Vocab - Bigram**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hoo4gJCUI5-5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_frequency_bigram(dataset):\n",
        "  word_frequency = {}\n",
        "  for sent in dataset:\n",
        "      for ind, word1 in enumerate(sent[:-1]):\n",
        "          word2 = sent[ind+1]\n",
        "          if (word1,word2) not in word_frequency :\n",
        "              word_frequency[(word1,word2)] = 1\n",
        "          else:\n",
        "              val = word_frequency[(word1,word2)]\n",
        "              val += 1\n",
        "              word_frequency[(word1,word2)] = val\n",
        "              \n",
        "  #word_to_ix['UNKNOWN'] = len(word_to_ix)\n",
        "  return word_frequency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S3s-0e2ZI5-_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "THRESHOLD_FREQUENCY = 5\n",
        "\n",
        "def reduce_vocab_bigram(word_frequency):\n",
        "  word_to_ix = {}\n",
        "  for (word1,word2) in word_frequency:\n",
        "    val = word_frequency[(word1,word2)]\n",
        "    if val >= THRESHOLD_FREQUENCY:\n",
        "      word_to_ix[(word1,word2)] = len(word_to_ix)\n",
        "  word_to_ix['UNKNOWN'] = len(word_to_ix)\n",
        "  return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d5b37b1a-72a3-40fd-9635-1b3d4c713879",
        "id": "DaciC_xAI5_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_frequency_bigram = generate_word_frequency_bigram(train_data_X + test_data_X)\n",
        "word_to_ix_bigram = reduce_vocab_bigram(word_frequency_bigram)\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix_bigram)\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RGTL4048YaVP"
      },
      "cell_type": "markdown",
      "source": [
        "Store the word index once created"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "T-tSn3VHYaVW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"word_to_ix_bigram.pickle\",\"wb\")\n",
        "pickle.dump(word_to_ix_bigram, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "from google.colab import files\n",
        "model = files.download(\"word_to_ix_bigram.pickle\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSxdwxYkVhGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Irrelevant for this Task. Remove it later"
      ]
    },
    {
      "metadata": {
        "id": "kazPiVAVXN8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61946e0b-d932-4a14-c906-46cc61ec863e"
      },
      "cell_type": "code",
      "source": [
        "label_to_ix = {1: 1, 0: 0}\n",
        "ix_to_label = {v: k for k, v in label_to_ix.items()}\n",
        "\n",
        "label_to_ix, ix_to_label"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 0, 1: 1}, {0: 0, 1: 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "jz4FQIi9Vprm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Pytorch initialization**"
      ]
    },
    {
      "metadata": {
        "id": "gam4OsAEaAYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99943fc9-7413-44e9-9f54-8aeac269b90e"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.device('cuda')\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "cm5Quj5MWMWT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Create bow vectors**"
      ]
    },
    {
      "metadata": {
        "id": "EkTB1W04rzlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import time\n",
        "\n",
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[ word_to_ix['UNKNOWN'] ] += 1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    #print(label)\n",
        "    return torch.LongTensor([label_to_ix[label]])\n",
        "\n",
        "bow_vec_orig = []\n",
        "for instance in train_data_X:\n",
        "  ins_bow_vector = make_bow_vector(instance, word_to_ix)\n",
        "  bow_vec_orig.append(Variable(ins_bow_vector).cuda())\n",
        "bow_vec_orig = torch.stack(bow_vec_orig).cuda()\n",
        "  \n",
        "label_orig = []\n",
        "for l in train_data_Y:\n",
        "  label_vector = make_target(l, label_to_ix)\n",
        "  label_orig.append(Variable(label_vector).cuda())\n",
        "label_orig = torch.stack(label_orig).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5uKZBGwbNPwb"
      },
      "cell_type": "markdown",
      "source": [
        "#**Create bow vectors - Bigram**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CrystbBeNPwc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import time\n",
        "\n",
        "def make_bow_vector_bigram(sentence, word_to_ix_bigram):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix_bigram))\n",
        "    for ind,word1 in enumerate(sentence[:-1]):\n",
        "        word2 = sentence[ind+1]\n",
        "        if (word1, word2) not in word_to_ix_bigram:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            #vec[ word_to_ix_bigram['UNKNOWN'] ] += 1\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix_bigram[(word1, word2)]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    #print(label)\n",
        "    return torch.LongTensor([label_to_ix[label]])\n",
        "\n",
        "bow_vec_bgram_orig = []\n",
        "for instance in train_data_X:\n",
        "  ins_bow_vector = make_bow_vector_bigram(instance, word_to_ix_bigram)\n",
        "  bow_vec_bgram_orig.append(Variable(ins_bow_vector).cuda())\n",
        "bow_vec_bgram_orig = torch.stack(bow_vec_bgram_orig).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xk74JKQguSEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Functions to train model and find metrics**"
      ]
    },
    {
      "metadata": {
        "id": "AaSZzouOuaMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "  \n",
        "def train(task, loss_function, opt):\n",
        "  bow_vec = bow_vec_orig[:]\n",
        "  label = label_orig[:]\n",
        "  # the training loop\n",
        "  for epoch in range(10):\n",
        "      start = time.time()\n",
        "      for ind, instance in enumerate(train_data_X):\n",
        "          task.zero_grad()\n",
        "          probs = task(bow_vec[ind]) # forward pass\n",
        "          loss = loss_function(probs, label[ind])\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "      end = time.time()\n",
        "      print('Time Taken - ' + str(end - start))\n",
        "      print('Epoch - ' + str(epoch) + ' , LOSS - ' + str(loss.data))\n",
        "  return task\n",
        "      \n",
        "def calculateMetrics(task):\n",
        "  print('--- AFTER TRAINING ---')\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "\n",
        "  for ind, instance in enumerate(test_data_X):\n",
        "      bow_vec = Variable(make_bow_vector(instance, word_to_ix)).cuda()\n",
        "      logprobs = task(bow_vec)\n",
        "      pred = np.argmax(logprobs.cpu().data.numpy())\n",
        "      label = test_data_Y[ind]\n",
        "      if label == 1 and ix_to_label[pred] == 1:\n",
        "        tp += 1\n",
        "      elif label == 1 and ix_to_label[pred] == 0:\n",
        "        fn += 1\n",
        "      elif label == 0 and ix_to_label[pred] == 0:\n",
        "        tn += 1\n",
        "      else:\n",
        "        fp += 1\n",
        "\n",
        "  accuracy = float(tp+tn)/ len(test_data_X)\n",
        "  recall = float(tp)/ (tp+fn)\n",
        "  precision = float(tp)/ (tp+fp)\n",
        "  fmeasure = float(2*recall*precision) / (precision+recall)\n",
        "  \n",
        "  print('Accuracy - ' + str(accuracy))\n",
        "  print('Recall - ' + str(recall))\n",
        "  print('Precision - ' + str(precision))\n",
        "  print('Fmeasure - ' + str(fmeasure))\n",
        "  \n",
        "def save_model(task, name):\n",
        "  torch.save(task,name)\n",
        "  files.download(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M35VUK3sWyiV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 1**"
      ]
    },
    {
      "metadata": {
        "id": "644dEiuvcWgi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task1(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons, vocab_size):\n",
        "    super(Task1, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons, num_labels)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    return F.softmax(self.lin2(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUTGZVOlXpQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 1 A"
      ]
    },
    {
      "metadata": {
        "id": "J6sPZeBWXoFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS = 50\n",
        "  \n",
        "task1a = Task1(NUM_LABELS, HIDDEN_LAYER_NEURONS, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function1a = nn.NLLLoss()\n",
        "opt1a = torch.optim.SGD(task1a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3DkuVPRyX_Cv"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 1 B"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k4j-OQAvX_C9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS = 100\n",
        "  \n",
        "task1b = Task1(NUM_LABELS, HIDDEN_LAYER_NEURONS, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function1b = nn.NLLLoss()\n",
        "opt1b = torch.optim.SGD(task1b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mG5XNa6IYJxY"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 1 C"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FYxOD6sYYJxd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS = 150\n",
        "  \n",
        "task1c = Task1(NUM_LABELS, HIDDEN_LAYER_NEURONS, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function1c = nn.NLLLoss()\n",
        "opt1c = torch.optim.SGD(task1c.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tdgm10ohW__r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 1**"
      ]
    },
    {
      "metadata": {
        "id": "fAi16mE9YS4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 1 a**"
      ]
    },
    {
      "metadata": {
        "id": "BJHsSrF3hiG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "id": "0eI_RB90kvjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "4ebaed92-1280-4741-b9a2-db2bf87e8b76"
      },
      "cell_type": "code",
      "source": [
        "task = train(task1a, loss_function1a, opt1a)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 16.32853102684021\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.219228982925415\n",
            "Epoch - 1 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.209766626358032\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.11113142967224\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.14791774749756\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.643018007278442\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.039944171905518\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.057997465133667\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.17435932159424\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.094764709472656\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.868\n",
            "Recall - 0.8705321683876092\n",
            "Precision - 0.8677751385589866\n",
            "Fmeasure - 0.8691514670896114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8VLa2_1shAB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ca79407d-62fe-43e4-a86e-e064ded7c562"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_1a.mdl')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task1. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4sNM2Y97v9Uc"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 1 b**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QMkFXCWdv56q"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aHjwrSwmv56v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "5ea3056f-03b3-46e4-b324-06ece7edcfb2"
      },
      "cell_type": "code",
      "source": [
        "task = train(task1b, loss_function1b, opt1b)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 16.44837236404419\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.170080184936523\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.250499725341797\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.150915145874023\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.178941249847412\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 17.09151005744934\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.30715847015381\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.360268354415894\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.28510856628418\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.321537971496582\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8698\n",
            "Recall - 0.891977760127085\n",
            "Precision - 0.8556190476190476\n",
            "Fmeasure - 0.8734201827727007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U4KHGJ0ZhKCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "36d857b4-3b2f-4461-9ad6-99e45a77bc7a"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_1b.mdl')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task1. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Gy3ugE1qv-KE"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 1 c**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "R4njkhDBv6bw"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BexLEpzVv6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "db1b1d5c-df7b-46a2-e2ed-1e6f5fc8a1c2"
      },
      "cell_type": "code",
      "source": [
        "task = train(task1c, loss_function1c, opt1c)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 16.621872901916504\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.347761631011963\n",
            "Epoch - 1 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.811615228652954\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.191262006759644\n",
            "Epoch - 3 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.209725856781006\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.18377161026001\n",
            "Epoch - 5 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 16.166773080825806\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.199344158172607\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.161771774291992\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 16.147169589996338\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8666\n",
            "Recall - 0.8613979348689436\n",
            "Precision - 0.8721351025331725\n",
            "Fmeasure - 0.8667332667332667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AznqoCkBhMnc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cfd2927c-31f8-4b3c-b6ff-174adf21b02d"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_1c.mdl')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task1. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aq524mr7MoBE"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 2**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ypC8WVQNMoBH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, vocab_size):\n",
        "    super(Task2, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    return F.softmax(self.lin3(out))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3PTPWy1tMoBP"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 2 A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VEsBV7e0MoBR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 10\n",
        "HIDDEN_LAYER_NEURONS2 = 10\n",
        "  \n",
        "task2a = Task2(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function2a = nn.NLLLoss()\n",
        "opt2a = torch.optim.SGD(task2a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BpMdnIJMNS3V"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 2 B"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h9QAy-XQNS3a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 20\n",
        "HIDDEN_LAYER_NEURONS2 = 10\n",
        "  \n",
        "task2b = Task2(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function2b = nn.NLLLoss()\n",
        "opt2b = torch.optim.SGD(task2b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uRZ6LcbNNdUl"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 2 C"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W2J9yyHmNdUp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 30\n",
        "  \n",
        "task2c = Task2(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function2c = nn.NLLLoss()\n",
        "opt2c = torch.optim.SGD(task2c.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fjGIG33gNkbD"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 2 D"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "guB7IDPoNkbG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 50\n",
        "HIDDEN_LAYER_NEURONS2 = 50\n",
        "  \n",
        "task2d = Task2(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function2d = nn.NLLLoss()\n",
        "opt2d = torch.optim.SGD(task2d.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OxaDf4fsNrH4"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 2 E"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aqmmjwR4NrIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 100\n",
        "HIDDEN_LAYER_NEURONS2 = 50\n",
        "  \n",
        "task2e = Task2(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function2e = nn.NLLLoss()\n",
        "opt2e = torch.optim.SGD(task2e.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFpsSZ27JptA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 2**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wmyrJwnIwTmh"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 2 a**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4D4UuYvYwTmk"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DeiIAKRBwTmu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "19097491-e636-4762-edb7-905e0f7aa71b"
      },
      "cell_type": "code",
      "source": [
        "task = train(task2a, loss_function2a, opt2a)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.332382678985596\n",
            "Epoch - 0 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.249682903289795\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.878215789794922\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.553465843200684\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.411340475082397\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.410038471221924\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.605851888656616\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.357484579086304\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.44930624961853\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.380980491638184\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8486\n",
            "Recall - 0.903494837172359\n",
            "Precision - 0.8157045536034421\n",
            "Fmeasure - 0.8573582061428301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c-I_W9QyhQIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f17de941-0dab-4fbc-bf6c-6da6a9242e7c"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_2a.mdl')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HmQXWu69wUS2"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 2 b**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "C9HefqZhwUS6"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XWLlzs9VwUS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "884a1472-2209-4cc8-dc59-6e87b737d762"
      },
      "cell_type": "code",
      "source": [
        "task = train(task2b, loss_function2b, opt2b)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.613932371139526\n",
            "Epoch - 0 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.29813027381897\n",
            "Epoch - 1 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 20.358999490737915\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.37652039527893\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.391200304031372\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.37814736366272\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.308969020843506\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.433732509613037\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.464009046554565\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.343831777572632\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8436\n",
            "Recall - 0.8018268467037332\n",
            "Precision - 0.8770634231103388\n",
            "Fmeasure - 0.8377593360995851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ig-apd5PhoqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a8ccd25-ca08-4b7b-93d2-81ad8099077a"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_2b.mdl')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "icidGAIkwV7i"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 2c**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WxJQoiwfwV7l"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3crABKPswV76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "0bf3db8e-a8c1-41a6-a88b-ef4589ff8a99"
      },
      "cell_type": "code",
      "source": [
        "task = train(task2c, loss_function2c, opt2c)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.927616119384766\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 20.341686964035034\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.189078330993652\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.60692286491394\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.986009120941162\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.11312508583069\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.151569843292236\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.112948656082153\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.098836660385132\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.17791199684143\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8588\n",
            "Recall - 0.8629864972200159\n",
            "Precision - 0.8575374901341752\n",
            "Fmeasure - 0.8602533650039589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vrgCXq2ahtQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ccfee724-f8fa-40b2-b65b-494391ee26ed"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_2c.mdl')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GyGg6NdQwWig"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 2 d**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NgrbdrjKwWil"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tvu48eQxwWio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "c28ab842-9d5d-4bb8-a621-3ecf91a0b574"
      },
      "cell_type": "code",
      "source": [
        "task = train(task2d, loss_function2d, opt2d)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.10313367843628\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 20.005864143371582\n",
            "Epoch - 1 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 19.86429762840271\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.96662211418152\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.580289363861084\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.09446930885315\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.0238299369812\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.43057107925415\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.105145692825317\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.001198053359985\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.858\n",
            "Recall - 0.892374900714853\n",
            "Precision - 0.836559940431869\n",
            "Fmeasure - 0.8635664873174481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UOObRlLkhv2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2b0ec203-1044-422d-b15d-22228f19941c"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_2d.mdl')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0hfUJxqNwXGp"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 2 e**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "O35rBH8LwXGw"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E54KBM10wXGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "56967119-6183-4a40-bab9-3e7c3b0c5146"
      },
      "cell_type": "code",
      "source": [
        "task = train(task2e, loss_function2e, opt2e)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.08453941345215\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 20.026304483413696\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.976668119430542\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.97039771080017\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.02477788925171\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.99086332321167\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.005309104919434\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.02510380744934\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 19.977061986923218\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.671231746673584\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8546\n",
            "Recall - 0.8776806989674345\n",
            "Precision - 0.8406238113351084\n",
            "Fmeasure - 0.8587526714591024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c9MGiOhVh0jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fb1615c3-29fa-4f44-ba31-c67bd178dd36"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_2e.mdl')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U1nvWbPu3fNt"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 3**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x5yGKC3k3fN1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task3(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task3, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "    self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    return F.softmax(self.lin4(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InK4KfWr3fOA"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 3 A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TWQTuAzA3fOG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 100\n",
        "HIDDEN_LAYER_NEURONS2 = 50\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task3a = Task3(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function3a = nn.NLLLoss()\n",
        "opt3a = torch.optim.SGD(task3a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DYNUrHq-42LJ"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 3 B"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uWNkugVx42LP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 200\n",
        "HIDDEN_LAYER_NEURONS2 = 100\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task3b = Task3(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function3b = nn.NLLLoss()\n",
        "opt3b = torch.optim.SGD(task3b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "079wE3iL5FuU"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 3**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lwDYBc-z5Fue"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 3 a**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AjXSpNsk5Fui"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GRqlxpxM5Fun",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "b909737e-1b85-465d-ee8b-9b5bfa8e09f7"
      },
      "cell_type": "code",
      "source": [
        "task = train(task3a, loss_function3a, opt3a)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 24.067967891693115\n",
            "Epoch - 0 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.127845287322998\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 23.986689567565918\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.021493673324585\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.00989270210266\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.25253391265869\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.2269868850708\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.105911254882812\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.07929039001465\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 23.9444317817688\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8398\n",
            "Recall - 0.9007148530579825\n",
            "Precision - 0.8045406172401561\n",
            "Fmeasure - 0.8499156829679595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6gD3_R2-h8u_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "66ec4dbc-86fe-410e-df30-1805750604b6"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_3a.mdl')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task3. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Vjymw3pT5P25"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 3 b**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hefWONuA5P2-"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iv_gqpTX5P3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "d0b3d877-1836-43f1-db43-019b66e75a1b"
      },
      "cell_type": "code",
      "source": [
        "task = train(task3b, loss_function3b, opt3b)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 24.582305908203125\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 24.514402151107788\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.35111165046692\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.364917516708374\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.37273335456848\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.252920150756836\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.342594861984253\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.94948935508728\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.57725191116333\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.809766054153442\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8126\n",
            "Recall - 0.6894360603653693\n",
            "Precision - 0.9180327868852459\n",
            "Fmeasure - 0.7874801542299841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dpjAlpo5A3mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8c2b218d-3b4b-4416-defe-7fd98531df0b"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_3b.mdl')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task3. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4O3OPX1F-Okl"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 4**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H3k9RHcB-Okq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task4(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task4, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r4h40Z1x-Ok3"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 4 A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_AXNpuBw-Ok7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task4a = Task4(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function4a = nn.NLLLoss()\n",
        "opt4a = torch.optim.SGD(task4a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vpVu6TMYAXQl"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 4 B"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "47na0ItBAXQp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 100\n",
        "HIDDEN_LAYER_NEURONS2 = 100\n",
        "  \n",
        "task4b = Task4(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, None, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function4b = nn.NLLLoss()\n",
        "opt4b = torch.optim.SGD(task4b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RMu4qAlUAoMp"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 4 C"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YnHGLZMkAoMv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 100\n",
        "HIDDEN_LAYER_NEURONS2 = 10\n",
        "  \n",
        "task4c = Task4(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, None, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function4c = nn.NLLLoss()\n",
        "opt4c = torch.optim.SGD(task4c.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Lah5sUjUBp8k"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 4**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jVnm0KXZBp8n"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 4 a**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Mj3kKhGwBp8o"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qxwCVBSHBp8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "5370ca44-1536-4451-88d7-d5b36b76249a"
      },
      "cell_type": "code",
      "source": [
        "task = train(task4a, loss_function4a, opt4a)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 24.308379888534546\n",
            "Epoch - 0 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.271718502044678\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.03266429901123\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.091163873672485\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.035337209701538\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.033724546432495\n",
            "Epoch - 5 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 24.09830665588379\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.136087656021118\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.061615705490112\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 24.016504049301147\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8554\n",
            "Recall - 0.846306592533757\n",
            "Precision - 0.8638021888933928\n",
            "Fmeasure - 0.8549648946840522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ron4qmOtBp8v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5ffd806c-224a-4e3b-99e9-d658727132ff"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_4a.mdl')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TeRJVxOIB0Aq"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 4  b**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8OgB-ixNB0As"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NcGT6eHUB0As",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "03b14a85-f0fc-48d3-becc-1e9e14a0837c"
      },
      "cell_type": "code",
      "source": [
        "task = train(task4b, loss_function4b, opt4b)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 21.187002420425415\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 21.189964056015015\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.934136629104614\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.837417602539062\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.840358018875122\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.716098308563232\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.734814882278442\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.773621082305908\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.857794046401978\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.91875171661377\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8438\n",
            "Recall - 0.8836378077839555\n",
            "Precision - 0.8201253225211943\n",
            "Fmeasure - 0.8506977633339706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ISGlPvl6B0A5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b8899dd0-3f12-44c0-8f4a-32db18ae618b"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_4b.mdl')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zT7LfM_rB-eZ"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 4  c**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GqVwLKtbB-ee"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7wWKLUBTB-eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "b9029847-9dd5-48fe-9946-f2a69faaff97"
      },
      "cell_type": "code",
      "source": [
        "task = train(task4c, loss_function4c, opt4c)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 20.954166412353516\n",
            "Epoch - 0 , LOSS - tensor(-1.0000, device='cuda:0')\n",
            "Time Taken - 20.848313331604004\n",
            "Epoch - 1 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.835992336273193\n",
            "Epoch - 2 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.892149925231934\n",
            "Epoch - 3 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.897969245910645\n",
            "Epoch - 4 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.770830869674683\n",
            "Epoch - 5 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.764296054840088\n",
            "Epoch - 6 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 20.794527530670166\n",
            "Epoch - 7 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 21.391910791397095\n",
            "Epoch - 8 , LOSS - tensor(-1., device='cuda:0')\n",
            "Time Taken - 21.16739511489868\n",
            "Epoch - 9 , LOSS - tensor(-1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8506\n",
            "Recall - 0.8907863383637807\n",
            "Precision - 0.8261510128913444\n",
            "Fmeasure - 0.8572520542709727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wEdkumrrB-eo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19e75d7f-2e5c-4bad-e03c-413410806d56"
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_4c.mdl')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "J72D9cOelDlZ"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 5**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e_X1DfQwlDla",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task5a(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task5a, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))\n",
        "    \n",
        "class Task5b(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task5b, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.tanh(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))\n",
        "    \n",
        "class Task5c(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task5c, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.sigmoid(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sOkUrmpWlDle"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 5 A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iFY9XY56lDlg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task5a = Task5a(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function5a = nn.NLLLoss()\n",
        "opt5a = torch.optim.SGD(task5a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OGbxX8ObmiH1"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 5 B"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HkxH4fLVmiH6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task5b = Task5b(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function5b = nn.NLLLoss()\n",
        "opt5b = torch.optim.SGD(task5b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9PYGc4wbmjAb"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 5 C"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CgYEDGI7mjAg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task5c = Task5c(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function5c = nn.NLLLoss()\n",
        "opt5c = torch.optim.SGD(task5c.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6yFv7dE-RJuP"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 6**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6uYRUPqLRJuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task6(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task6, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JhSewFkDRJuT"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nB9Kp6ixRJuT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task6 = Task6(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function6 = nn.NLLLoss()\n",
        "opt6 = torch.optim.SGD(task6.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "H1lvycO-RmRH"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 6**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "A0NJPi2PRmRI"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 6**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cpaNc1aMRmRJ"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WlN87ClxRmRK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task = train(task6, loss_function6, opt6)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5ffd806c-224a-4e3b-99e9-d658727132ff",
        "id": "bSHAbNOFRmRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_6.mdl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uE09kr0dapm5"
      },
      "cell_type": "markdown",
      "source": [
        "#**Neural network for Task 7**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "duN32ZpRapm_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task7(nn.Module):\n",
        "  def __init__(self, num_labels, hidden_layer_neurons1, hidden_layer_neurons2, hidden_layer_neurons3, vocab_size):\n",
        "    super(Task7, self).__init__()\n",
        "    self.lin1 = nn.Linear(vocab_size, hidden_layer_neurons1)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    self.lin2 = nn.Linear(hidden_layer_neurons1, hidden_layer_neurons2)\n",
        "    torch.nn.Dropout(0.5)\n",
        "    if hidden_layer_neurons3 is not None:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, hidden_layer_neurons3)\n",
        "      torch.nn.Dropout(0.5)\n",
        "      self.lin4 = nn.Linear(hidden_layer_neurons3, num_labels)\n",
        "    else:\n",
        "      self.lin3 = nn.Linear(hidden_layer_neurons2, num_labels)\n",
        "      self.lin4 = None\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.lin1(x)\n",
        "    out = F.relu(self.lin2(out))\n",
        "    out = self.lin3(out)\n",
        "    if self.lin4 is None:\n",
        "      return F.softmax(out)\n",
        "    else:\n",
        "      return F.softmax(self.lin4(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MmDWXN3vapnP"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 7a"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_zfIeMLkapnY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task7a = Task7(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function7a = nn.CrossEntropyLoss()\n",
        "opt7a = torch.optim.SGD(task7a.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XRCOxpaIcAgN"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 7b"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FUflumUmcAgS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task7b = Task7(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function7b = nn.MSELoss()\n",
        "opt7b = torch.optim.SGD(task7b.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "daUKLpckcCuZ"
      },
      "cell_type": "markdown",
      "source": [
        "Setting model parameters for Task 7c"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3G6iNKwRcCud",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2  \n",
        "HIDDEN_LAYER_NEURONS1 = 30\n",
        "HIDDEN_LAYER_NEURONS2 = 20\n",
        "HIDDEN_LAYER_NEURONS3 = 10\n",
        "  \n",
        "task7c = Task7(NUM_LABELS, HIDDEN_LAYER_NEURONS1, HIDDEN_LAYER_NEURONS2, HIDDEN_LAYER_NEURONS3, VOCAB_SIZE).cuda()\n",
        "# define a loss function and an optimizer\n",
        "loss_function7c = nn.HingeEmbeddingLoss()\n",
        "opt7c = torch.optim.SGD(task7c.parameters(), lr = 0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rC_SQFVIclBb"
      },
      "cell_type": "markdown",
      "source": [
        "#**Training for Task 7**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lfyQiGvKclBh"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 7 a**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eMXZD_K3clBl"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4c6173b1-620b-49c3-c27c-cedbb16ae687",
        "id": "xYlpH1wNclBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "task = train(task7a, loss_function7a, opt7a)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 25.428458213806152\n",
            "Epoch - 0 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.342161655426025\n",
            "Epoch - 1 , LOSS - tensor(0.3136, device='cuda:0')\n",
            "Time Taken - 25.43352437019348\n",
            "Epoch - 2 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.365437984466553\n",
            "Epoch - 3 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.402482986450195\n",
            "Epoch - 4 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.489394187927246\n",
            "Epoch - 5 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.39272165298462\n",
            "Epoch - 6 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.402258157730103\n",
            "Epoch - 7 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.493067741394043\n",
            "Epoch - 8 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "Time Taken - 25.804034948349\n",
            "Epoch - 9 , LOSS - tensor(0.3133, device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.8652\n",
            "Recall - 0.8856235107227959\n",
            "Precision - 0.8524464831804281\n",
            "Fmeasure - 0.8687183482664589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9b074d7c-4962-4ec8-82f9-c429ae1c732a",
        "id": "KygOAZfDclB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_7a.mdl')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task7. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5VZNtKBkczB7"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 7 b**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bQJHtWhcczCD"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MuWNzYvZczCH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task = train(task7b, loss_function7b, opt7b)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5ffd806c-224a-4e3b-99e9-d658727132ff",
        "id": "l7eKgy93czCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_7b.mdl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xkminaRIc0ON"
      },
      "cell_type": "markdown",
      "source": [
        "**Task 7 c**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hAl1bgPXc0OR"
      },
      "cell_type": "markdown",
      "source": [
        "*TRAINING*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MLKpCBlvc0OU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "6dcbc6ee-c75f-4945-ace0-5804f9e8742a"
      },
      "cell_type": "code",
      "source": [
        "task = train(task7c, loss_function7c, opt7c)\n",
        "calculateMetrics(task)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken - 33.00462055206299\n",
            "Epoch - 0 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.24803566932678\n",
            "Epoch - 1 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.04449462890625\n",
            "Epoch - 2 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.094396352767944\n",
            "Epoch - 3 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.16407775878906\n",
            "Epoch - 4 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 31.97115182876587\n",
            "Epoch - 5 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.02061724662781\n",
            "Epoch - 6 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.06936430931091\n",
            "Epoch - 7 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 32.247437715530396\n",
            "Epoch - 8 , LOSS - tensor(1., device='cuda:0')\n",
            "Time Taken - 31.875512838363647\n",
            "Epoch - 9 , LOSS - tensor(1., device='cuda:0')\n",
            "--- AFTER TRAINING ---\n",
            "Accuracy - 0.5036\n",
            "Recall - 1.0\n",
            "Precision - 0.5036\n",
            "Fmeasure - 0.6698590050545358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5ffd806c-224a-4e3b-99e9-d658727132ff",
        "id": "wK3mkkgbc0O2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "save_model(task.cpu(), 'model_7c.mdl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task4. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "C5tLQ-kQksRk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_BfeotFkp4_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "bow = torch.load(io.BytesIO(temp_test['model.json']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AeGRHDybXVIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-vkLqHTXWzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle_in = open(\"word_to_ix.pickle\",\"rb\")\n",
        "word_to_ix = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scWyKiVLL8Rh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}